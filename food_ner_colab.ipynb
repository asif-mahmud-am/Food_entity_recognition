{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asif-mahmud-am/Food_entity_recognition/blob/main/food_ner_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6d2ed717",
      "metadata": {
        "id": "6d2ed717"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "xXMVcA8k6kJJ"
      },
      "id": "xXMVcA8k6kJJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "060acc1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "060acc1f",
        "outputId": "d44a929c-8b57-41bd-e471-a2a93ea7740c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    fdc_id          data_type  \\\n",
              "0  1105904       branded_food   \n",
              "1  1105905       branded_food   \n",
              "2  1105906       branded_food   \n",
              "3  1105907       branded_food   \n",
              "4  1105898  experimental_food   \n",
              "\n",
              "                                         description  food_category_id  \\\n",
              "0                         WESSON Vegetable Oil 1 GAL               NaN   \n",
              "1                                 SWANSON BROTH BEEF               NaN   \n",
              "2           CAMPBELL'S SLOW KETTLE SOUP CLAM CHOWDER               NaN   \n",
              "3        CAMPBELL'S SLOW KETTLE SOUP CHEESE BROCCOLI               NaN   \n",
              "4  Discrepancy between the Atwater factor predict...               NaN   \n",
              "\n",
              "  publication_date  \n",
              "0       2020-11-13  \n",
              "1       2020-11-13  \n",
              "2       2020-11-13  \n",
              "3       2020-11-13  \n",
              "4       2020-10-30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35fb46a4-a142-455f-8dc3-01f195129b71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fdc_id</th>\n",
              "      <th>data_type</th>\n",
              "      <th>description</th>\n",
              "      <th>food_category_id</th>\n",
              "      <th>publication_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1105904</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>WESSON Vegetable Oil 1 GAL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1105905</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>SWANSON BROTH BEEF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1105906</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>CAMPBELL'S SLOW KETTLE SOUP CLAM CHOWDER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1105907</td>\n",
              "      <td>branded_food</td>\n",
              "      <td>CAMPBELL'S SLOW KETTLE SOUP CHEESE BROCCOLI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-11-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1105898</td>\n",
              "      <td>experimental_food</td>\n",
              "      <td>Discrepancy between the Atwater factor predict...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-10-30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35fb46a4-a142-455f-8dc3-01f195129b71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35fb46a4-a142-455f-8dc3-01f195129b71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35fb46a4-a142-455f-8dc3-01f195129b71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# read in the food csv file\n",
        "food_df = pd.read_csv(\"/content/drive/MyDrive/ner_food/food.csv\")\n",
        "\n",
        "# print row and column information\n",
        "food_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMeKWcDLRBjZ",
        "outputId": "9e0c4da8-e45e-4a95-b3b0-5630970f0180"
      },
      "id": "vMeKWcDLRBjZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "debc7539",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "debc7539",
        "outputId": "7c209bf5-8ff9-4cb9-a562-6dc661fa2601"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1605401"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# print the size \n",
        "food_df[\"description\"].size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "63f4c8a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63f4c8a6",
        "outputId": "0a9ddcc0-3c31-4320-ddee-e49d04d06301"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1605401, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "food_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5acd06a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5acd06a8",
        "outputId": "e45c8ad7-6f26-4997-9dbe-2d0b206b3be2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "390080"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(food_df[\"description\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51e6f90c",
      "metadata": {
        "id": "51e6f90c"
      },
      "source": [
        "We have way more rows than we need, so let's:\n",
        "\n",
        "Disqualify foods with special characters (+,&, !, , and so on).\n",
        "Filter out foods containing more than 3 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8bcc60c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bcc60c4",
        "outputId": "f994116a-1cb0-4a99-df49-badaaebe83a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41363"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# diaqualify foods with special characters, lowercase and extract results from \"description\" column\n",
        "foods = food_df[food_df[\"description\"].str.contains(\"[^a-zA-Z ]\") == False][\"description\"].apply(lambda food: food.lower())\n",
        "\n",
        "# filter out foods with more than 3 words, drop any duplicates\n",
        "foods = foods[foods.str.split().apply(len) <= 3].drop_duplicates()\n",
        "\n",
        "# print the remaining size\n",
        "foods.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dcf376bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "dcf376bc",
        "outputId": "4e727307-216b-4f60-a339-0efa738c62c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# find one-worded, two-worded and three-worded foods\n",
        "one_worded_foods = foods[foods.str.split().apply(len) == 1]\n",
        "two_worded_foods = foods[foods.str.split().apply(len) == 2]\n",
        "three_worded_foods = foods[foods.str.split().apply(len) == 3]\n",
        "\n",
        "# create a bar plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar([1, 2, 3], [one_worded_foods.size, two_worded_foods.size, three_worded_foods.size])\n",
        "\n",
        "# label the x-axis instances\n",
        "ax.set_xticks([1, 2, 3])\n",
        "ax.set_xticklabels([\"one\", \"two\", \"three\"])\n",
        "\n",
        "# set the title and the xy-axis labels\n",
        "plt.title(\"Number of Words in Food Entities\")\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Food Entities\")\n",
        "\n",
        "# display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8aefc584",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aefc584",
        "outputId": "a638dc68-014f-4bf4-e75a-bfa4e9886e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-worded food entities: 1443\n",
            "2-worded food entities: 962\n",
            "3-worded food entities: 802\n"
          ]
        }
      ],
      "source": [
        "# total number of foods\n",
        "total_num_foods = round(one_worded_foods.size / 45 * 100)\n",
        "\n",
        "# shuffle the 2-worded and 3-worded foods since we'll be slicing them\n",
        "two_worded_foods = two_worded_foods.sample(frac=1)\n",
        "three_worded_foods = three_worded_foods.sample(frac=1)\n",
        "\n",
        "# append the foods together \n",
        "foods = one_worded_foods.append(two_worded_foods[:round(total_num_foods * 0.30)]).append(three_worded_foods[:round(total_num_foods * 0.25)])\n",
        "\n",
        "# print the resulting sizes\n",
        "for i in range(3):\n",
        "    print(f\"{i+1}-worded food entities:\", foods[foods.str.split().apply(len) == i + 1].size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "687a7ad7",
      "metadata": {
        "id": "687a7ad7"
      },
      "outputs": [],
      "source": [
        "food_templates = [\n",
        "    \"I ate my {}\",\n",
        "    \"I'm eating a {}\",\n",
        "    \"I just ate a {}\",\n",
        "    \"I only ate the {}\",\n",
        "    \"I'm done eating a {}\",\n",
        "    \"I've already eaten a {}\",\n",
        "    \"I just finished my {}\",\n",
        "    \"When I was having lunch I ate a {}\",\n",
        "    \"I had a {} and a {} today\",\n",
        "    \"I ate a {} and a {} for lunch\",\n",
        "    \"I made a {} and {} for lunch\",\n",
        "    \"I ate {} and {}\",\n",
        "    \"today I ate a {} and a {} for lunch\",\n",
        "    \"I had {} with my husband last night\",\n",
        "    \"I brought you some {} on my birthday\",\n",
        "    \"I made {} for yesterday's dinner\",\n",
        "    \"last night, a {} was sent to me with {}\",\n",
        "    \"I had {} yesterday and I'd like to eat it anyway\",\n",
        "    \"I ate a couple of {} last night\",\n",
        "    \"I had some {} at dinner last night\",\n",
        "    \"Last night, I ordered some {}\",\n",
        "    \"I made a {} last night\",\n",
        "    \"I had a bowl of {} with {} and I wanted to go to the mall today\",\n",
        "    \"I brought a basket of {} for breakfast this morning\",\n",
        "    \"I had a bowl of {}\",\n",
        "    \"I ate a {} with {} in the morning\",\n",
        "    \"I made a bowl of {} for my breakfast\",\n",
        "    \"There's {} for breakfast in the bowl this morning\",\n",
        "    \"This morning, I made a bowl of {}\",\n",
        "    \"I decided to have some {} as a little bonus\",\n",
        "    \"I decided to enjoy some {}\",\n",
        "    \"I've decided to have some {} for dessert\",\n",
        "    \"I had a {}, a {} and {} at home\",\n",
        "    \"I took a {}, {} and {} on the weekend\",\n",
        "    \"I ate a {} with {} and {} just now\",\n",
        "    \"Last night, I ate an {} with {} and {}\",\n",
        "    \"I tasted some {}, {} and {} at the office\",\n",
        "    \"There's a basket of {}, {} and {} that I consumed\",\n",
        "    \"I devoured a {}, {} and {}\",\n",
        "    \"I've already had a bag of {}, {} and {} from the fridge\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2c0cddb1",
      "metadata": {
        "id": "2c0cddb1"
      },
      "outputs": [],
      "source": [
        "# create dictionaries to store the generated food combinations. Do note that one_food != one_worded_food. one_food == \"barbecue sauce\", one_worded_food == \"sauce\"\n",
        "TRAIN_FOOD_DATA = {\n",
        "    \"one_food\": [],\n",
        "    \"two_foods\": [],\n",
        "    \"three_foods\": []\n",
        "}\n",
        "\n",
        "TEST_FOOD_DATA = {\n",
        "    \"one_food\": [],\n",
        "    \"two_foods\": [],\n",
        "    \"three_foods\": []\n",
        "}\n",
        "\n",
        "# one_food, two_food, and three_food combinations will be limited to 167 sentences\n",
        "FOOD_SENTENCE_LIMIT = 167\n",
        "\n",
        "# helper function for deciding what dictionary and subsequent array to append the food sentence on to\n",
        "def get_food_data(count):\n",
        "    return {\n",
        "        1: TRAIN_FOOD_DATA[\"one_food\"] if len(TRAIN_FOOD_DATA[\"one_food\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"one_food\"],\n",
        "        2: TRAIN_FOOD_DATA[\"two_foods\"] if len(TRAIN_FOOD_DATA[\"two_foods\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"two_foods\"],\n",
        "        3: TRAIN_FOOD_DATA[\"three_foods\"] if len(TRAIN_FOOD_DATA[\"three_foods\"]) < FOOD_SENTENCE_LIMIT else TEST_FOOD_DATA[\"three_foods\"],\n",
        "    }[count]\n",
        "\n",
        "# the pattern to replace from the template sentences\n",
        "pattern_to_replace = \"{}\"\n",
        "\n",
        "# shuffle the data before starting\n",
        "foods = foods.sample(frac=1)\n",
        "\n",
        "# the count that helps us decide when to break from the for loop\n",
        "food_entity_count = foods.size - 1\n",
        "\n",
        "# start the while loop, ensure we don't get an index out of bounds error\n",
        "while food_entity_count >= 2:\n",
        "    entities = []\n",
        "\n",
        "    # pick a random food template\n",
        "    sentence = food_templates[random.randint(0, len(food_templates) - 1)]\n",
        "\n",
        "    # find out how many braces \"{}\" need to be replaced in the template\n",
        "    matches = re.findall(pattern_to_replace, sentence)\n",
        "\n",
        "    # for each brace, replace with a food entity from the shuffled food data\n",
        "    for match in matches:\n",
        "        food = foods.iloc[food_entity_count]\n",
        "        food_entity_count -= 1\n",
        "\n",
        "        # replace the pattern, but then find the match of the food entity we just inserted\n",
        "        sentence = sentence.replace(match, food, 1)\n",
        "        match_span = re.search(food, sentence).span()\n",
        "\n",
        "        # use that match to find the index positions of the food entity in the sentence, append\n",
        "        entities.append((match_span[0], match_span[1], \"FOOD\"))\n",
        "\n",
        "    # append the sentence and the position of the entities to the correct dictionary and array\n",
        "    get_food_data(len(matches)).append((sentence, {\"entities\": entities}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "70b91460",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70b91460",
        "outputId": "af7c8531-e0ca-4876-d33a-6dec5dfc91b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167 one_food sentences: ('I made a bowl of lemon ginger kombucha for my breakfast', {'entities': [(17, 38, 'FOOD')]})\n",
            "167 two_foods sentences: ('I made a gourmet bread crumbs and original cheesecake sampler for lunch', {'entities': [(9, 29, 'FOOD'), (34, 61, 'FOOD')]})\n",
            "167 three_foods sentences: ('I took a pie, pork cracklin strips and estafiate on the weekend', {'entities': [(9, 12, 'FOOD'), (14, 34, 'FOOD'), (39, 48, 'FOOD')]})\n"
          ]
        }
      ],
      "source": [
        "# print the number of food sentences, as well as an example sentence\n",
        "for key in TRAIN_FOOD_DATA:\n",
        "    print(\"{} {} sentences: {}\".format(len(TRAIN_FOOD_DATA[key]), key, TRAIN_FOOD_DATA[key][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b8e8791e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8e8791e",
        "outputId": "6151bb83-b941-4787-fc90-6f18679fcafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1055 one_food items: ('I brought a basket of shake for breakfast this morning', {'entities': [(22, 27, 'FOOD')]})\n",
            "214 two_foods items: ('I ate party wings and garlic stuffed olives', {'entities': [(6, 17, 'FOOD'), (22, 43, 'FOOD')]})\n",
            "240 three_foods items: ('Last night, I ate an tequesquite with heart and soul and licorice', {'entities': [(21, 32, 'FOOD'), (38, 52, 'FOOD'), (57, 65, 'FOOD')]})\n"
          ]
        }
      ],
      "source": [
        "for key in TEST_FOOD_DATA:\n",
        "    print(\"{} {} items: {}\".format(len(TEST_FOOD_DATA[key]), key, TEST_FOOD_DATA[key][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "acf14716",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "acf14716",
        "outputId": "26f4ff9c-3538-47ee-8094-6e4da9f1ec02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Article\n",
              "0  In the Washington of 2016, even when the polic...\n",
              "1    Donald Trump has used Twitter  —   his prefe...\n",
              "2    Donald Trump is unabashedly praising Russian...\n",
              "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
              "4  From photography, illustration and video, to d..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d701f54-4971-44f1-8e9b-614aa8e560f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the Washington of 2016, even when the polic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From photography, illustration and video, to d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d701f54-4971-44f1-8e9b-614aa8e560f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d701f54-4971-44f1-8e9b-614aa8e560f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d701f54-4971-44f1-8e9b-614aa8e560f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# read in the revision data (just used a random article dataset from a different course I had taken)\n",
        "npr_df = pd.read_csv(\"/content/drive/MyDrive/ner_food/npr.csv\")\n",
        "\n",
        "# print row and column information\n",
        "npr_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc15c0f1",
      "metadata": {
        "id": "fc15c0f1"
      },
      "outputs": [],
      "source": [
        "# create an nlp object as we'll use this to seperate the sentences and identify existing entities\n",
        "#nlp = en_core_web_lg.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7add108e",
      "metadata": {
        "id": "7add108e"
      },
      "outputs": [],
      "source": [
        "revision_texts = []\n",
        "\n",
        "# convert the articles to spacy objects to better identify the sentences. Disabled unneeded components. # takes ~ 4 minutes\n",
        "for doc in nlp.pipe(npr_df[\"Article\"][:6000], batch_size=30, disable=[\"tagger\", \"ner\"]):\n",
        "    for sentence in doc.sents:\n",
        "        if  40 < len(sentence.text) < 80:\n",
        "            # some of the sentences had excessive whitespace in between words, so we're trimming that\n",
        "            revision_texts.append(\" \".join(re.split(\"\\s+\", sentence.text, flags=re.UNICODE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "53369f52",
      "metadata": {
        "id": "53369f52"
      },
      "outputs": [],
      "source": [
        "revisions = []\n",
        "\n",
        "# Use the existing spaCy model to predict the entities, then append them to revision\n",
        "for doc in nlp.pipe(revision_texts, batch_size=50, disable=[\"tagger\", \"parser\"]):\n",
        "    \n",
        "    # don't append sentences that have no entities\n",
        "    if len(doc.ents) > 0:\n",
        "        revisions.append((doc.text, {\"entities\": [(e.start_char, e.end_char, e.label_) for e in doc.ents]}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7533f74a",
      "metadata": {
        "id": "7533f74a"
      },
      "source": [
        "# Split train and test revision data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2bc0ad89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bc0ad89",
        "outputId": "f5ec53e1-4eeb-4279-942f-8cf124bee2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And in that sense, this year shows little sign of ending on Dec. 31.\n",
            "{'entities': [(19, 28, 'DATE'), (60, 67, 'DATE')]}\n"
          ]
        }
      ],
      "source": [
        "# print an example of the revision sentence\n",
        "print(revisions[0][0])\n",
        "\n",
        "# print an example of the revision data\n",
        "print(revisions[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b512357a",
      "metadata": {
        "id": "b512357a"
      },
      "outputs": [],
      "source": [
        "# create arrays to store the revision data\n",
        "TRAIN_REVISION_DATA = []\n",
        "TEST_REVISION_DATA = []\n",
        "\n",
        "# create dictionaries to keep count of the different entities\n",
        "TRAIN_ENTITY_COUNTER = {}\n",
        "TEST_ENTITY_COUNTER = {}\n",
        "\n",
        "# This will help distribute the entities (i.e. we don't want 1000 PERSON entities, but only 80 ORG entities)\n",
        "REVISION_SENTENCE_SOFT_LIMIT = 100\n",
        "\n",
        "# helper function for incrementing the revision counters\n",
        "def increment_revision_counters(entity_counter, entities):\n",
        "    for entity in entities:\n",
        "        label = entity[2]\n",
        "        if label in entity_counter:\n",
        "            entity_counter[label] += 1\n",
        "        else:\n",
        "            entity_counter[label] = 1\n",
        "\n",
        "random.shuffle(revisions)\n",
        "for revision in revisions:\n",
        "    # get the entities from the revision sentence\n",
        "    entities = revision[1][\"entities\"]\n",
        "\n",
        "    # simple hack to make sure spaCy entities don't get too one-sided\n",
        "    should_append_to_train_counter = 0\n",
        "    for _, _, label in entities:\n",
        "        if label in TRAIN_ENTITY_COUNTER and TRAIN_ENTITY_COUNTER[label] > REVISION_SENTENCE_SOFT_LIMIT:\n",
        "            should_append_to_train_counter -= 1\n",
        "        else:\n",
        "            should_append_to_train_counter += 1\n",
        "\n",
        "random.shuffle(revisions)\n",
        "for revision in revisions:\n",
        "    # get the entities from the revision sentence\n",
        "    entities = revision[1][\"entities\"]\n",
        "\n",
        "    # simple hack to make sure spaCy entities don't get too one-sided\n",
        "    should_append_to_train_counter = 0\n",
        "    for _, _, label in entities:\n",
        "        if label in TRAIN_ENTITY_COUNTER and TRAIN_ENTITY_COUNTER[label] > REVISION_SENTENCE_SOFT_LIMIT:\n",
        "            should_append_to_train_counter -= 1\n",
        "        else:\n",
        "            should_append_to_train_counter += 1\n",
        "\n",
        "    # simple switch for deciding whether to append to train data or test data\n",
        "    if should_append_to_train_counter >= 0:\n",
        "        TRAIN_REVISION_DATA.append(revision)\n",
        "        increment_revision_counters(TRAIN_ENTITY_COUNTER, entities)\n",
        "    else:\n",
        "        TEST_REVISION_DATA.append(revision)\n",
        "        increment_revision_counters(TEST_ENTITY_COUNTER, entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e77a1e71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e77a1e71",
        "outputId": "a7f5b0b5-4291-4dc6-ce18-7f0a2e9a0b9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CARDINAL': 166,\n",
              " 'DATE': 199,\n",
              " 'EVENT': 101,\n",
              " 'FAC': 101,\n",
              " 'GPE': 175,\n",
              " 'LANGUAGE': 75,\n",
              " 'LAW': 101,\n",
              " 'LOC': 101,\n",
              " 'MONEY': 101,\n",
              " 'NORP': 127,\n",
              " 'ORDINAL': 109,\n",
              " 'ORG': 196,\n",
              " 'PERCENT': 102,\n",
              " 'PERSON': 259,\n",
              " 'PRODUCT': 101,\n",
              " 'QUANTITY': 103,\n",
              " 'TIME': 110,\n",
              " 'WORK_OF_ART': 101}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "TRAIN_ENTITY_COUNTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "59701ad9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59701ad9",
        "outputId": "86d5e997-3030-4952-99fc-6fa740498fa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CARDINAL': 5435,\n",
              " 'DATE': 7661,\n",
              " 'EVENT': 95,\n",
              " 'FAC': 210,\n",
              " 'GPE': 6700,\n",
              " 'LANGUAGE': 21,\n",
              " 'LAW': 33,\n",
              " 'LOC': 847,\n",
              " 'MONEY': 551,\n",
              " 'NORP': 2959,\n",
              " 'ORDINAL': 1142,\n",
              " 'ORG': 10070,\n",
              " 'PERCENT': 464,\n",
              " 'PERSON': 13666,\n",
              " 'PRODUCT': 519,\n",
              " 'QUANTITY': 186,\n",
              " 'TIME': 892,\n",
              " 'WORK_OF_ART': 430}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "TEST_ENTITY_COUNTER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "998a23fc",
      "metadata": {
        "id": "998a23fc"
      },
      "source": [
        "# Training the NER Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "96cfa4ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96cfa4ca",
        "outputId": "e9c475eb-8c54-4955-9dc0-4e5fd24763c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOOD 501\n",
            "REVISION 1514\n",
            "COMBINED 2015\n"
          ]
        }
      ],
      "source": [
        "# combine the food training data\n",
        "TRAIN_FOOD_DATA_COMBINED = TRAIN_FOOD_DATA[\"one_food\"] + TRAIN_FOOD_DATA[\"two_foods\"] + TRAIN_FOOD_DATA[\"three_foods\"]\n",
        "\n",
        "# print the length of the food training data\n",
        "print(\"FOOD\", len(TRAIN_FOOD_DATA_COMBINED))\n",
        "\n",
        "# print the length of the revision training data\n",
        "print(\"REVISION\", len(TRAIN_REVISION_DATA))\n",
        "\n",
        "# join and print the combined length\n",
        "TRAIN_DATA = TRAIN_REVISION_DATA + TRAIN_FOOD_DATA_COMBINED\n",
        "print(\"COMBINED\", len(TRAIN_DATA))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2e90f95a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e90f95a",
        "outputId": "5024b185-bca9-4d5b-8319-04e9027e5e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (1/30) {'ner': 15627.393613052674}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (2/30) {'ner': 14875.36232184642}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (3/30) {'ner': 14677.240252177231}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (4/30) {'ner': 14481.481186022633}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (5/30) {'ner': 14379.15159595292}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (6/30) {'ner': 14380.906393502373}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (7/30) {'ner': 14141.892443245742}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (8/30) {'ner': 14126.370970500458}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (9/30) {'ner': 14002.952138321009}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (10/30) {'ner': 14022.205862694012}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (11/30) {'ner': 14018.431356478832}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (12/30) {'ner': 14117.57712172065}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (13/30) {'ner': 13930.948713876307}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (14/30) {'ner': 13862.658658311004}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (15/30) {'ner': 13969.553951803711}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (16/30) {'ner': 13906.150307348755}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (17/30) {'ner': 13796.570201071678}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (18/30) {'ner': 13810.854661261867}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (19/30) {'ner': 13775.553794831794}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (20/30) {'ner': 13690.856499668851}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (21/30) {'ner': 13863.87856005397}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (22/30) {'ner': 13890.098071498796}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (23/30) {'ner': 13833.283092912665}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (24/30) {'ner': 13653.27328935475}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (25/30) {'ner': 13690.017406772648}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (26/30) {'ner': 13811.17053541803}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (27/30) {'ner': 13793.379588361131}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (28/30) {'ner': 13427.9829371761}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (29/30) {'ner': 13715.588957753731}\n",
            "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the experimental `debug-data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug-data --help\n",
            "Losses (30/30) {'ner': 13841.00072832356}\n"
          ]
        }
      ],
      "source": [
        "# add NER to the pipeline and the new label\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "ner.add_label(\"FOOD\")\n",
        "\n",
        "# get the names of the components we want to disable during training\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "\n",
        "# start the training loop, only training NER\n",
        "epochs = 30\n",
        "optimizer = nlp.resume_training()\n",
        "with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
        "    sizes = compounding(1.0, 4.0, 1.001)\n",
        "    \n",
        "    # batch up the examples using spaCy's minibatc\n",
        "    for epoch in range(epochs):\n",
        "        examples = TRAIN_DATA\n",
        "        random.shuffle(examples)\n",
        "        batches = minibatch(examples, size=sizes)\n",
        "        losses = {}\n",
        "        \n",
        "        for batch in batches:\n",
        "            texts, annotations = zip(*batch)\n",
        "            try:\n",
        "              nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
        "            except Exception as error:\n",
        "                    print(error)\n",
        "                    continue\n",
        "\n",
        "        print(\"Losses ({}/{})\".format(epoch + 1, epochs), losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f8cea0d",
      "metadata": {
        "id": "9f8cea0d"
      },
      "source": [
        "# Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d5b12eb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "d5b12eb5",
        "outputId": "6e229f1d-f217-4962-8f67-5e4a6d7be5f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is looking at buying \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.K.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " startup for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# display sentence involving original entities\n",
        "spacy.displacy.render(nlp(\"Apple is looking at buying U.K. startup for $1 billion\"), style=\"ent\",jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display sentences involving food entity\n",
        "spacy.displacy.render(nlp(\"I had a hamburger and chips for lunch today.\"), style=\"ent\",jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "NIfU9PypZQF7",
        "outputId": "9636d422-2ae0-42c2-a535-d4aa8f30854b"
      },
      "id": "NIfU9PypZQF7",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I had a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    hamburger\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    chips\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
              "</mark>\n",
              " for lunch today.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a4670d94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "a4670d94",
        "outputId": "fbf6056a-8d9c-476a-d498-2729434f4691"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I had \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    chocolate ice cream\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
              "</mark>\n",
              " as a little treat for myself.</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "spacy.displacy.render(nlp(\"I had chocolate ice cream as a little treat for myself.\"), style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.displacy.render(nlp(\"I ordered basmati rice, leaf spinach and cheese from Tesco yesterday\"), style=\"ent\",jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "CtuxpIf9ZZ2F",
        "outputId": "c6b9e1fc-5bc8-4756-8870-f5abcc0bb0e9"
      },
      "id": "CtuxpIf9ZZ2F",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I ordered basmati rice, \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    leaf spinach\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    cheese\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
              "</mark>\n",
              " from \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " yesterday</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating Food Entities"
      ],
      "metadata": {
        "id": "XTX_Ocs6BgKj"
      },
      "id": "XTX_Ocs6BgKj"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5f090ab2",
      "metadata": {
        "id": "5f090ab2"
      },
      "outputs": [],
      "source": [
        "# dictionary to hold our evaluation data\n",
        "food_evaluation = {\n",
        "    \"one_food\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0,\n",
        "    },\n",
        "    \"two_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    },\n",
        "    \"three_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    }\n",
        "}\n",
        "\n",
        "word_evaluation = {\n",
        "    \"1_worded_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    },\n",
        "    \"2_worded_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    },\n",
        "    \"3_worded_foods\": {\n",
        "        \"correct\": 0,\n",
        "        \"total\": 0\n",
        "    }\n",
        "}\n",
        "\n",
        "# loop over data from our test food set (3 keys in total)\n",
        "for key in TEST_FOOD_DATA:\n",
        "    foods = TEST_FOOD_DATA[key]\n",
        "\n",
        "    for food in foods:\n",
        "        # extract the sentence and correct food entities according to our test data\n",
        "        sentence = food[0]\n",
        "        entities = food[1][\"entities\"]\n",
        "\n",
        "        # for each entity, use our updated model to make a prediction on the sentence\n",
        "        for entity in entities:\n",
        "            doc = nlp(sentence)\n",
        "            correct_text = sentence[entity[0]:entity[1]]\n",
        "            n_worded_food =  len(correct_text.split())\n",
        "\n",
        "            # if we find that there's a match for predicted entity and predicted text, increment correct counters\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ == entity[2] and ent.text == correct_text:\n",
        "                    food_evaluation[key][\"correct\"] += 1\n",
        "                    if n_worded_food > 0:\n",
        "                        word_evaluation[f\"{n_worded_food}_worded_foods\"][\"correct\"] += 1\n",
        "                    \n",
        "                    # this break is important, ensures that we're not double counting on a correct match\n",
        "                    break\n",
        "            \n",
        "            #  increment total counters after each entity loop\n",
        "            food_evaluation[key][\"total\"] += 1\n",
        "            if n_worded_food > 0:\n",
        "                word_evaluation[f\"{n_worded_food}_worded_foods\"][\"total\"] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1ee3daac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ee3daac",
        "outputId": "7c88dc19-9362-47b9-f21d-06b5a50b6518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_worded_foods: 91.51%\n",
            "2_worded_foods: 95.01%\n",
            "3_worded_foods: 93.26%\n",
            "---\n",
            "one_food: 90.24%\n",
            "two_foods: 96.03%\n",
            "three_foods: 95.28%\n",
            "\n",
            "Total: 93.01%\n"
          ]
        }
      ],
      "source": [
        "for key in word_evaluation:\n",
        "    correct = word_evaluation[key][\"correct\"]\n",
        "    total = word_evaluation[key][\"total\"]\n",
        "\n",
        "    print(f\"{key}: {correct / total * 100:.2f}%\")\n",
        "\n",
        "food_total_sum = 0\n",
        "food_correct_sum = 0\n",
        "\n",
        "print(\"---\")\n",
        "for key in food_evaluation:\n",
        "    correct = food_evaluation[key][\"correct\"]\n",
        "    total = food_evaluation[key][\"total\"]\n",
        "    \n",
        "    food_total_sum += total\n",
        "    food_correct_sum += correct\n",
        "\n",
        "    print(f\"{key}: {correct / total * 100:.2f}%\")\n",
        "\n",
        "print(f\"\\nTotal: {food_correct_sum/food_total_sum * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating Existing Entities"
      ],
      "metadata": {
        "id": "qOg4OHd1BvTQ"
      },
      "id": "qOg4OHd1BvTQ"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c0802fa8",
      "metadata": {
        "id": "c0802fa8"
      },
      "outputs": [],
      "source": [
        "# dictionary which will be populated with the entities and result information\n",
        "entity_evaluation = {}\n",
        "\n",
        "# helper function to udpate the entity_evaluation dictionary\n",
        "def update_results(entity, metric):\n",
        "    if entity not in entity_evaluation:\n",
        "        entity_evaluation[entity] = {\"correct\": 0, \"total\": 0}\n",
        "    \n",
        "    entity_evaluation[entity][metric] += 1\n",
        "\n",
        "# same as before, see if entities from test set match what spaCy currently predicts\n",
        "for data in TEST_REVISION_DATA:\n",
        "    sentence = data[0]\n",
        "    entities = data[1][\"entities\"]\n",
        "\n",
        "    for entity in entities:\n",
        "        doc = nlp(sentence)\n",
        "        correct_text = sentence[entity[0]:entity[1]]\n",
        "\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == entity[2] and ent.text == correct_text:\n",
        "                update_results(ent.label_, \"correct\")\n",
        "                break\n",
        "\n",
        "        update_results(entity[2], \"total\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f5ac561c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5ac561c",
        "outputId": "97b4473a-61dd-4750-b6db-550989211261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERSON | 62.91%\n",
            "WORK_OF_ART | 35.12%\n",
            "DATE | 64.48%\n",
            "ORG | 49.82%\n",
            "QUANTITY | 79.57%\n",
            "CARDINAL | 82.83%\n",
            "GPE | 67.73%\n",
            "NORP | 83.07%\n",
            "MONEY | 78.77%\n",
            "ORDINAL | 94.66%\n",
            "PERCENT | 92.24%\n",
            "TIME | 56.28%\n",
            "FAC | 47.14%\n",
            "PRODUCT | 62.04%\n",
            "LOC | 44.39%\n",
            "LANGUAGE | 90.48%\n",
            "EVENT | 50.53%\n",
            "LAW | 75.76%\n",
            "\n",
            "Overall accuracy: 64.93%\n"
          ]
        }
      ],
      "source": [
        "sum_total = 0\n",
        "sum_correct = 0\n",
        "\n",
        "for entity in entity_evaluation:\n",
        "    total = entity_evaluation[entity][\"total\"]\n",
        "    correct = entity_evaluation[entity][\"correct\"]\n",
        "\n",
        "    sum_total += total\n",
        "    sum_correct += correct\n",
        "    \n",
        "    print(\"{} | {:.2f}%\".format(entity, correct / total * 100))\n",
        "\n",
        "print()\n",
        "print(\"Overall accuracy: {:.2f}%\".format(sum_correct / sum_total * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f9a094",
      "metadata": {
        "id": "e3f9a094"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad2697f",
      "metadata": {
        "id": "bad2697f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "food_ner_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}